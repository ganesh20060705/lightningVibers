{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mDvQIC25lndg"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "for package in ['catboost', 'lightgbm', 'xgboost']:\n",
        "    try:\n",
        "        __import__(package)\n",
        "    except ImportError:\n",
        "        print(f\"Installing {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import KFold\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKYbj6UPrYr6",
        "outputId": "39dcd920-22bd-424b-f984-e801bdce5935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Train: (67200, 4), Test: (5900, 4), Interactions: (1048575, 11)\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "interactions = pd.read_csv(\"interactions.csv\")\n",
        "\n",
        "for df in [train, test, interactions]:\n",
        "    df[\"service_date\"] = pd.to_datetime(df[\"service_date\"], format=\"mixed\", dayfirst=True)\n",
        "interactions[\"interaction_date\"] = pd.to_datetime(interactions[\"interaction_date\"], format=\"mixed\", dayfirst=True)\n",
        "\n",
        "for col in [\"origin_hub_id\", \"destination_hub_id\"]:\n",
        "    for df in [train, test, interactions]:\n",
        "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
        "\n",
        "print(f\"âœ“ Train: {train.shape}, Test: {test.shape}, Interactions: {interactions.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD5MI3VmreX_"
      },
      "outputs": [],
      "source": [
        "# Multiple time windows for interactions\n",
        "def create_interaction_features(interactions_df, days_threshold):\n",
        "    \"\"\"Create interaction features for specific time window\"\"\"\n",
        "    filtered = interactions_df[interactions_df.days_before_service >= days_threshold].copy()\n",
        "\n",
        "    route_features = filtered.groupby([\"origin_hub_id\", \"destination_hub_id\"]).agg({\n",
        "        \"cumulative_commitments\": [\"mean\", \"max\", \"std\", \"sum\"],\n",
        "        \"cumulative_interest_signals\": [\"mean\", \"max\", \"std\", \"sum\"],\n",
        "    }).reset_index()\n",
        "    route_features.columns = [\"origin_hub_id\", \"destination_hub_id\"] + \\\n",
        "                             [f\"route_{days_threshold}d_c_{stat}\" for stat in [\"mean\", \"max\", \"std\", \"sum\"]] + \\\n",
        "                             [f\"route_{days_threshold}d_i_{stat}\" for stat in [\"mean\", \"max\", \"std\", \"sum\"]]\n",
        "    return route_features\n",
        "\n",
        "# Create features for different time windows\n",
        "route_15d = create_interaction_features(interactions, 15)\n",
        "route_30d = create_interaction_features(interactions, 30)\n",
        "route_7d = create_interaction_features(interactions, 7)\n",
        "\n",
        "# Recent trend features (last interactions before service)\n",
        "recent_inter = interactions[interactions.days_before_service <= 30].copy()\n",
        "route_recent = recent_inter.groupby([\"origin_hub_id\", \"destination_hub_id\"]).agg({\n",
        "    \"cumulative_commitments\": [\"last\", \"mean\", \"max\"],\n",
        "    \"cumulative_interest_signals\": [\"last\", \"mean\", \"max\"],\n",
        "    \"days_before_service\": [\"min\", \"mean\"]\n",
        "}).reset_index()\n",
        "route_recent.columns = [\"origin_hub_id\", \"destination_hub_id\",\n",
        "                        \"recent_c_last\", \"recent_c_mean\", \"recent_c_max\",\n",
        "                        \"recent_i_last\", \"recent_i_mean\", \"recent_i_max\",\n",
        "                        \"recent_days_min\", \"recent_days_mean\"]\n",
        "\n",
        "# Route statistics from training\n",
        "route_train = train.groupby([\"origin_hub_id\", \"destination_hub_id\"]).final_service_units.agg(\n",
        "    [\"mean\", \"median\", \"std\", \"count\", \"min\", \"max\"]\n",
        ").reset_index()\n",
        "route_train.columns = [\"origin_hub_id\", \"destination_hub_id\",\n",
        "                       \"route_mean\", \"route_median\", \"route_std\", \"route_count\", \"route_min\", \"route_max\"]\n",
        "\n",
        "# Hub statistics\n",
        "origin_stats = train.groupby(\"origin_hub_id\").final_service_units.agg(\n",
        "    [\"mean\", \"median\", \"std\", \"count\", \"min\", \"max\"]\n",
        ").reset_index()\n",
        "origin_stats.columns = [\"origin_hub_id\", \"o_mean\", \"o_median\", \"o_std\", \"o_count\", \"o_min\", \"o_max\"]\n",
        "\n",
        "dest_stats = train.groupby(\"destination_hub_id\").final_service_units.agg(\n",
        "    [\"mean\", \"median\", \"std\", \"count\", \"min\", \"max\"]\n",
        ").reset_index()\n",
        "dest_stats.columns = [\"destination_hub_id\", \"d_mean\", \"d_median\", \"d_std\", \"d_count\", \"d_min\", \"d_max\"]\n",
        "\n",
        "# Hub interaction patterns\n",
        "inter_15 = interactions[interactions.days_before_service >= 15].copy()\n",
        "\n",
        "origin_inter = inter_15.groupby(\"origin_hub_id\").agg({\n",
        "    \"cumulative_commitments\": [\"mean\", \"max\", \"std\"],\n",
        "    \"cumulative_interest_signals\": [\"mean\", \"max\", \"std\"],\n",
        "}).reset_index()\n",
        "origin_inter.columns = [\"origin_hub_id\", \"o_c_mean\", \"o_c_max\", \"o_c_std\", \"o_i_mean\", \"o_i_max\", \"o_i_std\"]\n",
        "\n",
        "dest_inter = inter_15.groupby(\"destination_hub_id\").agg({\n",
        "    \"cumulative_commitments\": [\"mean\", \"max\", \"std\"],\n",
        "    \"cumulative_interest_signals\": [\"mean\", \"max\", \"std\"],\n",
        "}).reset_index()\n",
        "dest_inter.columns = [\"destination_hub_id\", \"d_c_mean\", \"d_c_max\", \"d_c_std\", \"d_i_mean\", \"d_i_max\", \"d_i_std\"]\n",
        "\n",
        "# Hub metadata\n",
        "origin_meta = inter_15.groupby(\"origin_hub_id\")[[\"origin_region\", \"origin_hub_tier\"]].agg(\n",
        "    lambda x: x.mode()[0] if len(x.mode()) > 0 else \"unknown\"\n",
        ").reset_index()\n",
        "\n",
        "dest_meta = inter_15.groupby(\"destination_hub_id\")[[\"destination_region\", \"destination_hub_tier\"]].agg(\n",
        "    lambda x: x.mode()[0] if len(x.mode()) > 0 else \"unknown\"\n",
        ").reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3gpImeDkrhmA"
      },
      "outputs": [],
      "source": [
        "def add_temporal(df):\n",
        "    df[\"year\"] = df.service_date.dt.year\n",
        "    df[\"month\"] = df.service_date.dt.month\n",
        "    df[\"day\"] = df.service_date.dt.day\n",
        "    df[\"dow\"] = df.service_date.dt.dayofweek\n",
        "    df[\"quarter\"] = df.service_date.dt.quarter\n",
        "    df[\"week_of_year\"] = df.service_date.dt.isocalendar().week\n",
        "    df[\"is_weekend\"] = (df.dow >= 5).astype(int)\n",
        "    df[\"is_month_start\"] = (df.day <= 7).astype(int)\n",
        "    df[\"is_month_end\"] = (df.day >= 24).astype(int)\n",
        "    df[\"is_quarter_end\"] = df.month.isin([3, 6, 9, 12]).astype(int)\n",
        "\n",
        "    # Cyclical encoding\n",
        "    df[\"month_sin\"] = np.sin(2 * np.pi * df.month / 12)\n",
        "    df[\"month_cos\"] = np.cos(2 * np.pi * df.month / 12)\n",
        "    df[\"dow_sin\"] = np.sin(2 * np.pi * df.dow / 7)\n",
        "    df[\"dow_cos\"] = np.cos(2 * np.pi * df.dow / 7)\n",
        "    df[\"day_sin\"] = np.sin(2 * np.pi * df.day / 31)\n",
        "    df[\"day_cos\"] = np.cos(2 * np.pi * df.day / 31)\n",
        "\n",
        "    return df\n",
        "\n",
        "train = add_temporal(train)\n",
        "test = add_temporal(test)\n",
        "\n",
        "# Temporal patterns\n",
        "month_stats = train.groupby(\"month\").final_service_units.agg([\"mean\", \"std\", \"median\", \"min\", \"max\"]).reset_index()\n",
        "month_stats.columns = [\"month\", \"month_mean\", \"month_std\", \"month_median\", \"month_min\", \"month_max\"]\n",
        "\n",
        "dow_stats = train.groupby(\"dow\").final_service_units.agg([\"mean\", \"std\", \"median\"]).reset_index()\n",
        "dow_stats.columns = [\"dow\", \"dow_mean\", \"dow_std\", \"dow_median\"]\n",
        "\n",
        "quarter_stats = train.groupby(\"quarter\").final_service_units.agg([\"mean\", \"std\"]).reset_index()\n",
        "quarter_stats.columns = [\"quarter\", \"quarter_mean\", \"quarter_std\"]\n",
        "\n",
        "# Month-Route interaction\n",
        "month_route_stats = train.groupby([\"month\", \"origin_hub_id\", \"destination_hub_id\"]).final_service_units.agg(\n",
        "    [\"mean\", \"count\"]\n",
        ").reset_index()\n",
        "month_route_stats.columns = [\"month\", \"origin_hub_id\", \"destination_hub_id\", \"month_route_mean\", \"month_route_count\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STLSAqjZrlkW",
        "outputId": "a9bdd1d9-5bfb-4f92-9cc0-866d68d3a1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Features: Train (67200, 108), Test (5900, 108)\n"
          ]
        }
      ],
      "source": [
        "def enrich(df):\n",
        "    # Route features (multiple time windows)\n",
        "    df = df.merge(route_train, on=[\"origin_hub_id\", \"destination_hub_id\"], how=\"left\")\n",
        "    df = df.merge(route_15d, on=[\"origin_hub_id\", \"destination_hub_id\"], how=\"left\")\n",
        "    df = df.merge(route_30d, on=[\"origin_hub_id\", \"destination_hub_id\"], how=\"left\")\n",
        "    df = df.merge(route_7d, on=[\"origin_hub_id\", \"destination_hub_id\"], how=\"left\")\n",
        "    df = df.merge(route_recent, on=[\"origin_hub_id\", \"destination_hub_id\"], how=\"left\")\n",
        "\n",
        "    # Hub features\n",
        "    df = df.merge(origin_stats, on=\"origin_hub_id\", how=\"left\")\n",
        "    df = df.merge(dest_stats, on=\"destination_hub_id\", how=\"left\")\n",
        "    df = df.merge(origin_inter, on=\"origin_hub_id\", how=\"left\")\n",
        "    df = df.merge(dest_inter, on=\"destination_hub_id\", how=\"left\")\n",
        "    df = df.merge(origin_meta, on=\"origin_hub_id\", how=\"left\")\n",
        "    df = df.merge(dest_meta, on=\"destination_hub_id\", how=\"left\")\n",
        "\n",
        "    # Temporal features\n",
        "    df = df.merge(month_stats, on=\"month\", how=\"left\")\n",
        "    df = df.merge(dow_stats, on=\"dow\", how=\"left\")\n",
        "    df = df.merge(quarter_stats, on=\"quarter\", how=\"left\")\n",
        "    df = df.merge(month_route_stats, on=[\"month\", \"origin_hub_id\", \"destination_hub_id\"], how=\"left\")\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = enrich(train)\n",
        "test_df = enrich(test)\n",
        "\n",
        "# Global fallbacks\n",
        "global_mean = train.final_service_units.mean()\n",
        "global_std = train.final_service_units.std()\n",
        "global_median = train.final_service_units.median()\n",
        "\n",
        "# Smart imputation with hierarchy: route â†’ hub â†’ temporal â†’ global\n",
        "for df in [train_df, test_df]:\n",
        "    # Route-level (highest priority)\n",
        "    df[\"route_mean\"] = df[\"route_mean\"].fillna(\n",
        "        df.groupby([\"origin_hub_id\", \"destination_hub_id\"])[\"o_mean\"].transform(\"first\")\n",
        "    ).fillna(df[\"o_mean\"]).fillna(df[\"month_mean\"]).fillna(global_mean)\n",
        "\n",
        "    df[\"route_median\"] = df[\"route_median\"].fillna(df[\"o_median\"]).fillna(df[\"month_median\"]).fillna(global_median)\n",
        "    df[\"route_std\"] = df[\"route_std\"].fillna(df[\"o_std\"]).fillna(df[\"month_std\"]).fillna(global_std)\n",
        "\n",
        "    # Hub-level\n",
        "    df[\"o_mean\"] = df[\"o_mean\"].fillna(df[\"month_mean\"]).fillna(global_mean)\n",
        "    df[\"d_mean\"] = df[\"d_mean\"].fillna(df[\"month_mean\"]).fillna(global_mean)\n",
        "    df[\"o_std\"] = df[\"o_std\"].fillna(global_std)\n",
        "    df[\"d_std\"] = df[\"d_std\"].fillna(global_std)\n",
        "    df[\"o_median\"] = df[\"o_median\"].fillna(global_median)\n",
        "    df[\"d_median\"] = df[\"d_median\"].fillna(global_median)\n",
        "\n",
        "    # Month-route\n",
        "    df[\"month_route_mean\"] = df[\"month_route_mean\"].fillna(df[\"route_mean\"])\n",
        "\n",
        "    # Fill all numeric columns\n",
        "    for col in df.select_dtypes(include=[np.number]).columns:\n",
        "        if df[col].isnull().any():\n",
        "            df[col] = df[col].fillna(0)\n",
        "\n",
        "    # Temporal\n",
        "    df[\"month_mean\"] = df[\"month_mean\"].fillna(global_mean)\n",
        "    df[\"dow_mean\"] = df[\"dow_mean\"].fillna(global_mean)\n",
        "    df[\"quarter_mean\"] = df[\"quarter_mean\"].fillna(global_mean)\n",
        "\n",
        "# Create interaction features\n",
        "for df in [train_df, test_df]:\n",
        "    df[\"hub_avg\"] = (df[\"o_mean\"] + df[\"d_mean\"]) / 2\n",
        "    df[\"hub_diff\"] = df[\"o_mean\"] - df[\"d_mean\"]\n",
        "    df[\"hub_ratio\"] = df[\"o_mean\"] / (df[\"d_mean\"] + 1)\n",
        "    df[\"route_vs_hub\"] = df[\"route_mean\"] / (df[\"hub_avg\"] + 1)\n",
        "    df[\"commitment_ratio\"] = df[\"route_15d_c_mean\"] / (df[\"route_15d_i_mean\"] + 1)\n",
        "    df[\"recent_vs_historical\"] = df[\"recent_c_mean\"] / (df[\"route_15d_c_mean\"] + 1)\n",
        "    df[\"hub_interaction_strength\"] = df[\"o_c_mean\"] * df[\"d_c_mean\"]\n",
        "    df[\"route_popularity\"] = df[\"route_15d_c_sum\"] + df[\"route_15d_i_sum\"]\n",
        "\n",
        "# Encode categoricals\n",
        "cat_cols = [\"origin_region\", \"destination_region\", \"origin_hub_tier\", \"destination_hub_tier\"]\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([train_df[col], test_df[col]]).fillna(\"unknown\")\n",
        "    le.fit(combined)\n",
        "    train_df[col] = le.transform(train_df[col].fillna(\"unknown\"))\n",
        "    test_df[col] = le.transform(test_df[col].fillna(\"unknown\"))\n",
        "\n",
        "# Encode hub IDs\n",
        "for col in [\"origin_hub_id\", \"destination_hub_id\"]:\n",
        "    le = LabelEncoder()\n",
        "    combined = pd.concat([train_df[col], test_df[col]])\n",
        "    le.fit(combined)\n",
        "    train_df[col + \"_enc\"] = le.transform(train_df[col])\n",
        "    test_df[col + \"_enc\"] = le.transform(test_df[col])\n",
        "\n",
        "print(f\"âœ“ Features: Train {train_df.shape}, Test {test_df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MicFi6Bhrs2t",
        "outputId": "13404b2e-0a35-4a83-ed91-3a1df00d16af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Features: 104 columns\n"
          ]
        }
      ],
      "source": [
        "exclude = [\"service_date\", \"final_service_units\", \"service_key\", \"origin_hub_id\", \"destination_hub_id\"]\n",
        "features = [c for c in train_df.columns if c not in exclude]\n",
        "\n",
        "X = train_df[features].copy()\n",
        "y = train_df.final_service_units.copy()\n",
        "X_test = test_df[features].copy()\n",
        "\n",
        "print(f\"âœ“ Features: {len(features)} columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0ciaZLhrwDl",
        "outputId": "6d76c1fa-6fcd-492c-c98c-9fa5a7991fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "ðŸŽ¯ K-FOLD CROSS-VALIDATION TRAINING\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "FOLD 1/5\n",
            "======================================================================\n",
            "Train: 53760, Val: 13440\n",
            "\n",
            "[Fold 1] Training LightGBM...\n",
            "   MAE: 261.5687\n",
            "[Fold 1] Training XGBoost...\n",
            "   MAE: 255.6218\n",
            "[Fold 1] Training CatBoost...\n",
            "   MAE: 244.6397\n",
            "\n",
            "âœ¨ Fold 1 Ensemble MAE: 249.8675\n",
            "\n",
            "======================================================================\n",
            "FOLD 2/5\n",
            "======================================================================\n",
            "Train: 53760, Val: 13440\n",
            "\n",
            "[Fold 2] Training LightGBM...\n",
            "   MAE: 271.3213\n",
            "[Fold 2] Training XGBoost...\n",
            "   MAE: 261.3880\n",
            "[Fold 2] Training CatBoost...\n",
            "   MAE: 253.7790\n",
            "\n",
            "âœ¨ Fold 2 Ensemble MAE: 258.0515\n",
            "\n",
            "======================================================================\n",
            "FOLD 3/5\n",
            "======================================================================\n",
            "Train: 53760, Val: 13440\n",
            "\n",
            "[Fold 3] Training LightGBM...\n",
            "   MAE: 266.6723\n",
            "[Fold 3] Training XGBoost...\n",
            "   MAE: 260.0295\n",
            "[Fold 3] Training CatBoost...\n",
            "   MAE: 250.4105\n",
            "\n",
            "âœ¨ Fold 3 Ensemble MAE: 254.9920\n",
            "\n",
            "======================================================================\n",
            "FOLD 4/5\n",
            "======================================================================\n",
            "Train: 53760, Val: 13440\n",
            "\n",
            "[Fold 4] Training LightGBM...\n",
            "   MAE: 265.0039\n",
            "[Fold 4] Training XGBoost...\n",
            "   MAE: 255.7322\n",
            "[Fold 4] Training CatBoost...\n",
            "   MAE: 245.8679\n",
            "\n",
            "âœ¨ Fold 4 Ensemble MAE: 251.3138\n",
            "\n",
            "======================================================================\n",
            "FOLD 5/5\n",
            "======================================================================\n",
            "Train: 53760, Val: 13440\n",
            "\n",
            "[Fold 5] Training LightGBM...\n",
            "   MAE: 259.8517\n",
            "[Fold 5] Training XGBoost...\n",
            "   MAE: 253.2854\n",
            "[Fold 5] Training CatBoost...\n",
            "   MAE: 243.5734\n",
            "\n",
            "âœ¨ Fold 5 Ensemble MAE: 247.9288\n"
          ]
        }
      ],
      "source": [
        "n_folds = 5\n",
        "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "fold_scores = []\n",
        "test_preds_all = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"FOLD {fold}/{n_folds}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    X_train_fold = X.iloc[train_idx]\n",
        "    X_val_fold = X.iloc[val_idx]\n",
        "    y_train_fold = y.iloc[train_idx]\n",
        "    y_val_fold = y.iloc[val_idx]\n",
        "\n",
        "    print(f\"Train: {len(X_train_fold)}, Val: {len(X_val_fold)}\")\n",
        "\n",
        "    # Train ensemble for this fold\n",
        "    fold_val_preds = []\n",
        "    fold_test_preds = []\n",
        "    fold_model_maes = []\n",
        "\n",
        "    # Model 1: LightGBM\n",
        "    print(f\"\\n[Fold {fold}] Training LightGBM...\")\n",
        "    m1 = lgb.LGBMRegressor(\n",
        "        objective=\"mae\", n_estimators=3000, learning_rate=0.03,\n",
        "        num_leaves=100, max_depth=9, subsample=0.8, colsample_bytree=0.8,\n",
        "        min_child_samples=10, reg_alpha=0.5, reg_lambda=0.5,\n",
        "        random_state=42+fold, verbose=-1\n",
        "    )\n",
        "    m1.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)],\n",
        "           callbacks=[lgb.early_stopping(200, verbose=False)])\n",
        "    v1 = m1.predict(X_val_fold)\n",
        "    t1 = m1.predict(X_test)\n",
        "    mae1 = mean_absolute_error(y_val_fold, v1)\n",
        "    print(f\"   MAE: {mae1:.4f}\")\n",
        "    fold_val_preds.append(v1)\n",
        "    fold_test_preds.append(t1)\n",
        "    fold_model_maes.append(mae1)\n",
        "\n",
        "    # Model 2: XGBoost\n",
        "    print(f\"[Fold {fold}] Training XGBoost...\")\n",
        "    m2 = xgb.XGBRegressor(\n",
        "        objective=\"reg:absoluteerror\", n_estimators=3000, learning_rate=0.03,\n",
        "        max_depth=9, subsample=0.8, colsample_bytree=0.8,\n",
        "        reg_alpha=0.5, reg_lambda=0.5, random_state=43+fold, verbosity=0\n",
        "    )\n",
        "    m2.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)], verbose=False)\n",
        "    v2 = m2.predict(X_val_fold)\n",
        "    t2 = m2.predict(X_test)\n",
        "    mae2 = mean_absolute_error(y_val_fold, v2)\n",
        "    print(f\"   MAE: {mae2:.4f}\")\n",
        "    fold_val_preds.append(v2)\n",
        "    fold_test_preds.append(t2)\n",
        "    fold_model_maes.append(mae2)\n",
        "\n",
        "    # Model 3: CatBoost\n",
        "    print(f\"[Fold {fold}] Training CatBoost...\")\n",
        "    m3 = CatBoostRegressor(\n",
        "        loss_function=\"MAE\", iterations=3000, learning_rate=0.03, depth=9,\n",
        "        l2_leaf_reg=5, random_seed=44+fold, verbose=False\n",
        "    )\n",
        "    m3.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold),\n",
        "           early_stopping_rounds=200, verbose=False)\n",
        "    v3 = m3.predict(X_val_fold)\n",
        "    t3 = m3.predict(X_test)\n",
        "    mae3 = mean_absolute_error(y_val_fold, v3)\n",
        "    print(f\"   MAE: {mae3:.4f}\")\n",
        "    fold_val_preds.append(v3)\n",
        "    fold_test_preds.append(t3)\n",
        "    fold_model_maes.append(mae3)\n",
        "\n",
        "    # Weighted ensemble for this fold\n",
        "    weights = np.array([1/mae for mae in fold_model_maes])\n",
        "    weights = weights / weights.sum()\n",
        "\n",
        "    fold_ensemble_val = sum(w * pred for w, pred in zip(weights, fold_val_preds))\n",
        "    fold_ensemble_test = sum(w * pred for w, pred in zip(weights, fold_test_preds))\n",
        "\n",
        "    fold_mae = mean_absolute_error(y_val_fold, fold_ensemble_val)\n",
        "    print(f\"\\nâœ¨ Fold {fold} Ensemble MAE: {fold_mae:.4f}\")\n",
        "\n",
        "    fold_scores.append(fold_mae)\n",
        "    test_preds_all.append(fold_ensemble_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYGjHBZaryzD",
        "outputId": "1e9fac4b-9eb6-4422-b885-81c6dae277a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "ðŸ”¥ FINAL ENSEMBLE\n",
            "======================================================================\n",
            "\n",
            "Cross-Validation Results:\n",
            "   Fold 1: 249.8675\n",
            "   Fold 2: 258.0515\n",
            "   Fold 3: 254.9920\n",
            "   Fold 4: 251.3138\n",
            "   Fold 5: 247.9288\n",
            "\n",
            "âœ¨ Average CV MAE: 252.4307 (+/- 3.6398)\n",
            "\n",
            "Calibration:\n",
            "   Adjustment: 5.49\n",
            "   Predictions: mean=1988.9, std=1046.2\n",
            "   Target:      mean=2001.7, std=1194.7\n"
          ]
        }
      ],
      "source": [
        "# Average predictions across all folds\n",
        "final_test_preds = np.mean(test_preds_all, axis=0)\n",
        "\n",
        "avg_cv_score = np.mean(fold_scores)\n",
        "std_cv_score = np.std(fold_scores)\n",
        "\n",
        "print(f\"\\nCross-Validation Results:\")\n",
        "for i, score in enumerate(fold_scores, 1):\n",
        "    print(f\"   Fold {i}: {score:.4f}\")\n",
        "print(f\"\\nâœ¨ Average CV MAE: {avg_cv_score:.4f} (+/- {std_cv_score:.4f})\")\n",
        "\n",
        "# Light calibration (less aggressive than before)\n",
        "train_mean = y.mean()\n",
        "pred_mean = final_test_preds.mean()\n",
        "adjustment = (train_mean - pred_mean) * 0.3  # Only 30% adjustment to reduce overfitting\n",
        "\n",
        "final_test_preds = final_test_preds + adjustment\n",
        "\n",
        "print(f\"\\nCalibration:\")\n",
        "print(f\"   Adjustment: {adjustment:.2f}\")\n",
        "print(f\"   Predictions: mean={final_test_preds.mean():.1f}, std={final_test_preds.std():.1f}\")\n",
        "print(f\"   Target:      mean={train_mean:.1f}, std={y.std():.1f}\")\n",
        "\n",
        "# Clip to safe range\n",
        "final_test_preds = np.clip(final_test_preds, y.min() * 0.8, y.max() * 1.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aH5f5UnsDMr",
        "outputId": "251fa9f8-505e-4d1f-d741-66ccd0f6b2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "SUBMISSION CREATED\n",
            "\n",
            " FINAL STATISTICS:\n",
            "   CV MAE: 252.4307 (+/- 3.6398)\n",
            "   Predictions: mean=1988.9, std=1046.2\n",
            "   Predictions: min=66, max=8577\n",
            "\n",
            "First 10 predictions:\n",
            "        service_key  final_service_units\n",
            "0  2025-02-11_46_45          3888.687677\n",
            "1  2025-01-20_17_23          1618.974891\n",
            "2  2025-01-08_02_14          1194.920319\n",
            "3  2025-01-08_08_47           847.954392\n",
            "4  2025-01-08_09_46          3094.590083\n",
            "5  2025-01-21_45_05          1368.470940\n",
            "6  2025-02-26_47_08          1367.945887\n",
            "7  2025-01-03_02_19          2481.110630\n",
            "8  2025-02-11_02_30          1490.038922\n",
            "9  2025-01-25_05_45          2548.422487\n"
          ]
        }
      ],
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"service_key\": test.service_key,\n",
        "    \"final_service_units\": final_test_preds\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(f\"\\n FINAL STATISTICS:\")\n",
        "print(f\"   CV MAE: {avg_cv_score:.4f} (+/- {std_cv_score:.4f})\")\n",
        "print(f\"   Predictions: mean={final_test_preds.mean():.1f}, std={final_test_preds.std():.1f}\")\n",
        "print(f\"   Predictions: min={final_test_preds.min():.0f}, max={final_test_preds.max():.0f}\")\n",
        "print(\"\\nFirst 10 predictions:\")\n",
        "print(submission.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVxNhve4tUsD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezifubNAtVSM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
